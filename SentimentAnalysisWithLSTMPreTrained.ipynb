{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysisWithLSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/TimSim/SentimentAnalysis/blob/master/SentimentAnalysisWithLSTMPreTrained.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "MYlAV3xgRygs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "0dbaacda-c99c-4d80-bd6d-37573d3cd273"
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cRjvEcC4SYNG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "6e9e6fef-56e1-47f2-e087-0701d6091847"
      },
      "cell_type": "code",
      "source": [
        "# After executing the cell above, Drive\n",
        "# files will be present in \"/content/drive/My Drive\".\n",
        "!ls -la \"/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 153538\n",
            "-rw------- 1 root root 25000128 Oct 16 01:31 idsMatrix2.npy\n",
            "-rw------- 1 root root 25000080 Oct  3 23:56 idsMatrix.npy\n",
            "drwx------ 2 root root     4096 Oct 12 21:13 models\n",
            "drwx------ 2 root root     4096 Oct 12 00:04 modelsOLD\n",
            "drwx------ 2 root root     4096 Oct 10 22:50 negativeReviews\n",
            "drwx------ 2 root root     4096 Oct 10 22:51 positiveReviews\n",
            "drwx------ 2 root root     4096 Oct 12 00:05 tensorboard\n",
            "-rw------- 1 root root 27200080 Oct  3 23:56 wordsList.npy\n",
            "-rw------- 1 root root 80000080 Oct  3 23:56 wordVectors.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YPRbk9kXTEMt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f1826a8f-1f78-4f2b-b758-24166f768ca9"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "wordsList = np.load('/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/wordsList.npy')\n",
        "print('Loaded the word list!')\n",
        "wordsList = wordsList.tolist() #Originally loaded as numpy array\n",
        "wordsList = [word.decode('UTF-8') for word in wordsList] #Encode words as UTF-8\n",
        "wordVectors = np.load('/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/wordVectors.npy')\n",
        "print ('Loaded the word vectors!')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded the word list!\n",
            "Loaded the word vectors!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F60FlIjGKFho",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7eeaeb64-8f55-4cb1-a2b3-42dd0f5d216e"
      },
      "cell_type": "code",
      "source": [
        "print(len(wordsList))\n",
        "print(wordVectors.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000\n",
            "(400000, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kUNFDmn4KJz_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "7201725d-2dd2-4102-ddce-26324a4b46cd"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "baseballIndex = wordsList.index('baseball')\n",
        "wordVectors[baseballIndex]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.9327  ,  1.0421  , -0.78515 ,  0.91033 ,  0.22711 , -0.62158 ,\n",
              "       -1.6493  ,  0.07686 , -0.5868  ,  0.058831,  0.35628 ,  0.68916 ,\n",
              "       -0.50598 ,  0.70473 ,  1.2664  , -0.40031 , -0.020687,  0.80863 ,\n",
              "       -0.90566 , -0.074054, -0.87675 , -0.6291  , -0.12685 ,  0.11524 ,\n",
              "       -0.55685 , -1.6826  , -0.26291 ,  0.22632 ,  0.713   , -1.0828  ,\n",
              "        2.1231  ,  0.49869 ,  0.066711, -0.48226 , -0.17897 ,  0.47699 ,\n",
              "        0.16384 ,  0.16537 , -0.11506 , -0.15962 , -0.94926 , -0.42833 ,\n",
              "       -0.59457 ,  1.3566  , -0.27506 ,  0.19918 , -0.36008 ,  0.55667 ,\n",
              "       -0.70315 ,  0.17157 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "7Uk3T7LwKM1R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "096c7ffa-30b4-40bb-88f5-27de3c1e3c0a"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "maxSeqLength = 10 #Maximum length of sentence\n",
        "numDimensions = 300 #Dimensions for each word vector\n",
        "firstSentence = np.zeros((maxSeqLength), dtype='int32')\n",
        "firstSentence[0] = wordsList.index(\"i\")\n",
        "firstSentence[1] = wordsList.index(\"thought\")\n",
        "firstSentence[2] = wordsList.index(\"the\")\n",
        "firstSentence[3] = wordsList.index(\"movie\")\n",
        "firstSentence[4] = wordsList.index(\"was\")\n",
        "firstSentence[5] = wordsList.index(\"incredible\")\n",
        "firstSentence[6] = wordsList.index(\"and\")\n",
        "firstSentence[7] = wordsList.index(\"inspiring\")\n",
        "#firstSentence[8] and firstSentence[9] are going to be 0\n",
        "print(firstSentence.shape)\n",
        "print(firstSentence) #Shows the row index for each word"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10,)\n",
            "[    41    804 201534   1005     15   7446      5  13767      0      0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "USeZFI1FKQNm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07a26090-86cd-48ae-e332-ab8ef2c2732e"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    print(tf.nn.embedding_lookup(wordVectors,firstSentence).eval().shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ckuJLljQKT8e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "6942959a-6010-4954-ce72-f239dea93379"
      },
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "positiveFiles = ['/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/positiveReviews/' + f for f in listdir('/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/positiveReviews/') if isfile(join('/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/positiveReviews/', f))]\n",
        "negativeFiles = ['/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/negativeReviews/' + f for f in listdir('/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/negativeReviews/') if isfile(join('/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/negativeReviews/', f))]\n",
        "numWords = []\n",
        "for pf in positiveFiles:\n",
        "    with open(pf, \"r\", encoding='utf-8') as f:\n",
        "        line=f.readline()\n",
        "        counter = len(line.split())\n",
        "        numWords.append(counter)       \n",
        "print('Positive files finished')\n",
        "\n",
        "for nf in negativeFiles:\n",
        "    with open(nf, \"r\", encoding='utf-8') as f:\n",
        "        line=f.readline()\n",
        "        counter = len(line.split())\n",
        "        numWords.append(counter)  \n",
        "print('Negative files finished')\n",
        "\n",
        "numFiles = len(numWords)\n",
        "print('The total number of files is', numFiles)\n",
        "print('The total number of words in the files is', sum(numWords))\n",
        "print('The average number of words in the files is', sum(numWords)/len(numWords))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive files finished\n",
            "Negative files finished\n",
            "The total number of files is 25000\n",
            "The total number of words in the files is 5844680\n",
            "The average number of words in the files is 233.7872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JThH5RGTdEsm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "90d22906-453d-4eba-d0c9-d4322407b2ef"
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.hist(numWords, 50)\n",
        "plt.xlabel('Sequence Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.axis([0, 1200, 0, 8000])\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3c80ec9c50b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumWords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sequence Length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Frequency'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'numWords' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "P01CbNAvd9-V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "maxSeqLength = 250"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tA7sQs01eEYN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "c6a52b0d-0d1e-4a8c-9344-50c58b1ba5c5"
      },
      "cell_type": "code",
      "source": [
        "fname = positiveFiles[3] #Can use any valid index (not just 3)\n",
        "with open(fname) as f:\n",
        "    for lines in f:\n",
        "        print(lines)\n",
        "        exit"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-7619b2ef209b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositiveFiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#Can use any valid index (not just 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlines\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mexit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'positiveFiles' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "4nPnBQxUeHK3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Removes punctuation, parentheses, question marks, etc., and leaves only alphanumeric characters\n",
        "import re\n",
        "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
        "\n",
        "def cleanSentences(string):\n",
        "    string = string.lower().replace(\"<br />\", \" \")\n",
        "    return re.sub(strip_special_chars, \"\", string.lower())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XQZBtMePfGsW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "7b395e64-a39b-4c24-c58c-e8eaaf5e9114"
      },
      "cell_type": "code",
      "source": [
        "firstFile = np.zeros((maxSeqLength), dtype='int32')\n",
        "with open(fname) as f:\n",
        "    indexCounter = 0\n",
        "    line=f.readline()\n",
        "    cleanedLine = cleanSentences(line)\n",
        "    split = cleanedLine.split()\n",
        "    for word in split:\n",
        "        if indexCounter < maxSeqLength:\n",
        "            try:\n",
        "                firstFile[indexCounter] = wordsList.index(word)\n",
        "            except ValueError:\n",
        "                firstFile[indexCounter] = 399999 #Vector for unknown words\n",
        "        indexCounter = indexCounter + 1\n",
        "firstFile"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  2660,     19, 201534,    538,    641,     15,   1922,    653,\n",
              "            5, 201534,    853,     12, 201534,   7732,      6, 201534,\n",
              "          974,   1612,    804,     20,     15,    120,   4862,     41,\n",
              "        93325,     33,    181,   2435,     61,  18903,     37,    319,\n",
              "           34,   6605,      4, 201534,   1069,     41,   3978,     20,\n",
              "            7,    530,     37,     14,      7,  12387,   1005,     20,\n",
              "        93325,    408,      4,   2274,     13,    285,     41,   3978,\n",
              "           20,     25, 201534,   1084,  10464,   6469,   1829,      7,\n",
              "          353,    883,     19, 201534,    410,   1395,     41,    269,\n",
              "         3779,    494,     25,     26,   3518,  13803,      6,     26,\n",
              "         2459, 123797,     36,      7,    530,      3,  10033,   8735,\n",
              "           46,    645,    117,     12,     34,     63,     32,     77,\n",
              "          871,  20720,   3468,      5,   1250,     37,     14,      7,\n",
              "          191,  19612,      5,    191,   1673,      4,   1716,    319,\n",
              "          191,   3885,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0,      0,      0,      0,      0,      0,      0,\n",
              "            0,      0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "o8Fkk9umfKJG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        " ids = np.zeros((numFiles, maxSeqLength), dtype='int32')\n",
        " fileCounter = 0\n",
        " for pf in positiveFiles:\n",
        "    with open(pf, \"r\") as f:\n",
        "        indexCounter = 0\n",
        "        line=f.readline()\n",
        "        cleanedLine = cleanSentences(line)\n",
        "        split = cleanedLine.split()\n",
        "        for word in split:\n",
        "            try:\n",
        "                ids[fileCounter][indexCounter] = wordsList.index(word)\n",
        "            except ValueError:\n",
        "                ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
        "            indexCounter = indexCounter + 1\n",
        "            if indexCounter >= maxSeqLength:\n",
        "                break\n",
        "        fileCounter = fileCounter + 1 \n",
        "\n",
        " for nf in negativeFiles:\n",
        "    with open(nf, \"r\") as f:\n",
        "        indexCounter = 0\n",
        "        line=f.readline()\n",
        "        cleanedLine = cleanSentences(line)\n",
        "        split = cleanedLine.split()\n",
        "        for word in split:\n",
        "            try:\n",
        "                ids[fileCounter][indexCounter] = wordsList.index(word)\n",
        "            except ValueError:\n",
        "                ids[fileCounter][indexCounter] = 399999 #Vector for unkown words\n",
        "            indexCounter = indexCounter + 1\n",
        "            if indexCounter >= maxSeqLength:\n",
        "                break\n",
        "        fileCounter = fileCounter + 1 \n",
        "# #Pass into embedding function and see if it evaluates. \n",
        "\n",
        "np.save('/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/idsMatrix2', ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F5YhKAWpfT4-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ids = np.load('/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/idsMatrix2.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1NTjIoIofqa_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "\n",
        "def getTrainBatch():\n",
        "    labels = []\n",
        "    arr = np.zeros([batchSize, maxSeqLength])\n",
        "    for i in range(batchSize):\n",
        "        if (i % 2 == 0): \n",
        "            num = randint(1,11499)\n",
        "            labels.append([1,0])\n",
        "        else:\n",
        "            num = randint(13499,24999)\n",
        "            labels.append([0,1])\n",
        "        arr[i] = ids[num-1:num]\n",
        "    return arr, labels\n",
        "\n",
        "def getTestBatch():\n",
        "    labels = []\n",
        "    arr = np.zeros([batchSize, maxSeqLength])\n",
        "    for i in range(batchSize):\n",
        "        num = randint(11499,13499)\n",
        "        if (num <= 12499):\n",
        "            labels.append([1,0])\n",
        "        else:\n",
        "            labels.append([0,1])\n",
        "        arr[i] = ids[num-1:num]\n",
        "    return arr, labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9Jh0QvrEfuQO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batchSize = 24\n",
        "lstmUnits = 64\n",
        "numClasses = 2\n",
        "iterations = 100000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wivSZpX8fwro",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.reset_default_graph()\n",
        "\n",
        "labels = tf.placeholder(tf.float32, [batchSize, numClasses])\n",
        "input_data = tf.placeholder(tf.int32, [batchSize, maxSeqLength])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s0Z9WE7PfzdO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = tf.Variable(tf.zeros([batchSize, maxSeqLength, numDimensions]),dtype=tf.float32)\n",
        "data = tf.nn.embedding_lookup(wordVectors,input_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q-VTUBxNf_0n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "c5005f6b-aeb7-45c9-89ad-b71eecd315be"
      },
      "cell_type": "code",
      "source": [
        "lstmCell = tf.contrib.rnn.BasicLSTMCell(lstmUnits)\n",
        "lstmCell = tf.contrib.rnn.DropoutWrapper(cell=lstmCell, output_keep_prob=0.75)\n",
        "value, _ = tf.nn.dynamic_rnn(lstmCell, data, dtype=tf.float32)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-20-db6a6fc2c55e>:1: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is deprecated, please use tf.nn.rnn_cell.LSTMCell, which supports all the feature this cell currently has. Please replace the existing code with tf.nn.rnn_cell.LSTMCell(name='basic_lstm_cell').\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xj01GzvzgFe_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "weight = tf.Variable(tf.truncated_normal([lstmUnits, numClasses]))\n",
        "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
        "value = tf.transpose(value, [1, 0, 2])\n",
        "last = tf.gather(value, int(value.get_shape()[0]) - 1)\n",
        "prediction = (tf.matmul(last, weight) + bias)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f4CnoKhugINf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "correctPred = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correctPred, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Toxa51hgKxW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "9dd5defb-9d85-4244-c7d3-2fbd8311f0f3"
      },
      "cell_type": "code",
      "source": [
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
        "optimizer = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-23-773132a4e1b5>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mE6jvcROgOqP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "tf.summary.scalar('Loss', loss)\n",
        "tf.summary.scalar('Accuracy', accuracy)\n",
        "merged = tf.summary.merge_all()\n",
        "logdir = \"/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
        "writer = tf.summary.FileWriter(logdir, sess.graph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zvgv5vfNgSKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "23bc7b57-a6d6-4f91-b523-0147c7d377a4"
      },
      "cell_type": "code",
      "source": [
        " sess = tf.InteractiveSession()\n",
        " saver = tf.train.Saver()\n",
        " sess.run(tf.global_variables_initializer())\n",
        "\n",
        " for i in range(iterations):\n",
        "    #Next Batch of reviews\n",
        "    nextBatch, nextBatchLabels = getTrainBatch();\n",
        "    sess.run(optimizer, {input_data: nextBatch, labels: nextBatchLabels})\n",
        "   \n",
        "    #Write summary to Tensorboard\n",
        "    if (i % 50 == 0):\n",
        "        summary = sess.run(merged, {input_data: nextBatch, labels: nextBatchLabels})\n",
        "        writer.add_summary(summary, i)\n",
        "\n",
        "    #Save the network every 10,000 training iterations\n",
        "    if (i % 10000 == 0 and i != 0):\n",
        "        save_path = saver.save(sess, \"/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/models/pretrained_lstm.ckpt\", global_step=i)\n",
        "        print(\"saved to %s\" % save_path)\n",
        " writer.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1662: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "bk2NpvzGgVjn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f5c43e3-be74-45e2-89a1-b92f48a64d8a"
      },
      "cell_type": "code",
      "source": [
        "sess = tf.InteractiveSession()\n",
        "saver = tf.train.Saver()\n",
        "saver.restore(sess, tf.train.latest_checkpoint('/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/models'))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/Colab Notebooks/sentimentAnalysis/models/pretrained_lstm.ckpt-90000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4aJpGBZsNH_3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "7100ea3b-9a9b-4cf1-8e9f-1e9af7022a31"
      },
      "cell_type": "code",
      "source": [
        "iterations = 10\n",
        "for i in range(iterations):\n",
        "    nextBatch, nextBatchLabels = getTestBatch();\n",
        "    print(\"Accuracy for this batch:\", (sess.run(accuracy, {input_data: nextBatch, labels: nextBatchLabels})) * 100)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy for this batch: 87.5\n",
            "Accuracy for this batch: 95.83333134651184\n",
            "Accuracy for this batch: 91.66666865348816\n",
            "Accuracy for this batch: 91.66666865348816\n",
            "Accuracy for this batch: 95.83333134651184\n",
            "Accuracy for this batch: 91.66666865348816\n",
            "Accuracy for this batch: 95.83333134651184\n",
            "Accuracy for this batch: 95.83333134651184\n",
            "Accuracy for this batch: 91.66666865348816\n",
            "Accuracy for this batch: 95.83333134651184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DznRGtPYN7Vc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Removes punctuation, parentheses, question marks, etc., and leaves only alphanumeric characters\n",
        "import re\n",
        "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
        "\n",
        "def cleanSentences(string):\n",
        "    string = string.lower().replace(\"<br />\", \" \")\n",
        "    return re.sub(strip_special_chars, \"\", string.lower())\n",
        "\n",
        "def getSentenceMatrix(sentence):\n",
        "    arr = np.zeros([batchSize, maxSeqLength])\n",
        "    sentenceMatrix = np.zeros([batchSize,maxSeqLength], dtype='int32')\n",
        "    cleanedSentence = cleanSentences(sentence)\n",
        "    split = cleanedSentence.split()\n",
        "    for indexCounter,word in enumerate(split):\n",
        "        try:\n",
        "            sentenceMatrix[0,indexCounter] = wordsList.index(word)\n",
        "        except ValueError:\n",
        "            sentenceMatrix[0,indexCounter] = 399999 #Vector for unkown words\n",
        "    return sentenceMatrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hnZYXVJEN-c5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inputText = \"That movie was good\"\n",
        "inputMatrix = getSentenceMatrix(inputText)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B0xbKKDAN_qR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be0b62f4-150d-4df7-8106-745e87ce537e"
      },
      "cell_type": "code",
      "source": [
        "predictedSentiment = sess.run(prediction, {input_data: inputMatrix})[0]\n",
        "# predictedSentiment[0] represents output score for positive sentiment\n",
        "# predictedSentiment[1] represents output score for negative sentiment\n",
        "\n",
        "if (predictedSentiment[0] > predictedSentiment[1]):\n",
        "    print (\"Positive Sentiment\")\n",
        "else:\n",
        "    print (\"Negative Sentiment\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive Sentiment\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}