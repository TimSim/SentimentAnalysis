{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysisWithLSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/TimSim/SentimentAnalysis/blob/master/SentimentAnalysisWithLSTM.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "MYlAV3xgRygs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "18732d75-255d-4286-e4b5-7c7d04d7ca52"
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cRjvEcC4SYNG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "38380db6-ff4d-4944-cec3-e5fd8aa04600"
      },
      "cell_type": "code",
      "source": [
        "# After executing the cell above, Drive\n",
        "# files will be present in \"/content/drive/My Drive\".\n",
        "!ls -la \"/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 104697\n",
            "drwx------ 2 root root     4096 Oct 10 22:50 negativeReviews\n",
            "drwx------ 2 root root     4096 Oct 10 22:51 positiveReviews\n",
            "-rw------- 1 root root 27200080 Oct  3 23:56 wordsList.npy\n",
            "-rw------- 1 root root 80000080 Oct  3 23:56 wordVectors.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YPRbk9kXTEMt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d0677d7c-3bcc-42c4-a9f7-5eeba66a3e03"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "wordsList = np.load('/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/wordsList.npy')\n",
        "print('Loaded the word list!')\n",
        "wordsList = wordsList.tolist() #Originally loaded as numpy array\n",
        "wordsList = [word.decode('UTF-8') for word in wordsList] #Encode words as UTF-8\n",
        "wordVectors = np.load('/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/wordVectors.npy')\n",
        "print ('Loaded the word vectors!')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded the word list!\n",
            "Loaded the word vectors!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F60FlIjGKFho",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "dedf3bc2-ccbf-46f1-f18e-a3588423390b"
      },
      "cell_type": "code",
      "source": [
        "print(len(wordsList))\n",
        "print(wordVectors.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000\n",
            "(400000, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kUNFDmn4KJz_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "cbf55c89-dea4-4442-8204-4937a3cbd615"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "baseballIndex = wordsList.index('baseball')\n",
        "wordVectors[baseballIndex]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.9327  ,  1.0421  , -0.78515 ,  0.91033 ,  0.22711 , -0.62158 ,\n",
              "       -1.6493  ,  0.07686 , -0.5868  ,  0.058831,  0.35628 ,  0.68916 ,\n",
              "       -0.50598 ,  0.70473 ,  1.2664  , -0.40031 , -0.020687,  0.80863 ,\n",
              "       -0.90566 , -0.074054, -0.87675 , -0.6291  , -0.12685 ,  0.11524 ,\n",
              "       -0.55685 , -1.6826  , -0.26291 ,  0.22632 ,  0.713   , -1.0828  ,\n",
              "        2.1231  ,  0.49869 ,  0.066711, -0.48226 , -0.17897 ,  0.47699 ,\n",
              "        0.16384 ,  0.16537 , -0.11506 , -0.15962 , -0.94926 , -0.42833 ,\n",
              "       -0.59457 ,  1.3566  , -0.27506 ,  0.19918 , -0.36008 ,  0.55667 ,\n",
              "       -0.70315 ,  0.17157 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "7Uk3T7LwKM1R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "da1e8bc9-4510-4ae6-f934-64b7a1edc648"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "maxSeqLength = 10 #Maximum length of sentence\n",
        "numDimensions = 300 #Dimensions for each word vector\n",
        "firstSentence = np.zeros((maxSeqLength), dtype='int32')\n",
        "firstSentence[0] = wordsList.index(\"i\")\n",
        "firstSentence[1] = wordsList.index(\"thought\")\n",
        "firstSentence[2] = wordsList.index(\"the\")\n",
        "firstSentence[3] = wordsList.index(\"movie\")\n",
        "firstSentence[4] = wordsList.index(\"was\")\n",
        "firstSentence[5] = wordsList.index(\"incredible\")\n",
        "firstSentence[6] = wordsList.index(\"and\")\n",
        "firstSentence[7] = wordsList.index(\"inspiring\")\n",
        "#firstSentence[8] and firstSentence[9] are going to be 0\n",
        "print(firstSentence.shape)\n",
        "print(firstSentence) #Shows the row index for each word"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10,)\n",
            "[    41    804 201534   1005     15   7446      5  13767      0      0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "USeZFI1FKQNm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "973ca45c-47fc-4c52-85bf-54aab3c424f4"
      },
      "cell_type": "code",
      "source": [
        "with tf.Session() as sess:\n",
        "    print(tf.nn.embedding_lookup(wordVectors,firstSentence).eval().shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ckuJLljQKT8e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "842417cb-b4b8-4988-a491-b09f9b966211"
      },
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "positiveFiles = ['/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/positiveReviews/' + f for f in listdir('/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/positiveReviews/') if isfile(join('/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/positiveReviews/', f))]\n",
        "negativeFiles = ['/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/negativeReviews/' + f for f in listdir('/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/negativeReviews/') if isfile(join('/content/drive/My Drive/Colab Notebooks/sentimentAnalysis/negativeReviews/', f))]\n",
        "numWords = []\n",
        "for pf in positiveFiles:\n",
        "    with open(pf, \"r\", encoding='utf-8') as f:\n",
        "        line=f.readline()\n",
        "        counter = len(line.split())\n",
        "        numWords.append(counter)       \n",
        "print('Positive files finished')\n",
        "\n",
        "for nf in negativeFiles:\n",
        "    with open(nf, \"r\", encoding='utf-8') as f:\n",
        "        line=f.readline()\n",
        "        counter = len(line.split())\n",
        "        numWords.append(counter)  \n",
        "print('Negative files finished')\n",
        "\n",
        "numFiles = len(numWords)\n",
        "print('The total number of files is', numFiles)\n",
        "print('The total number of words in the files is', sum(numWords))\n",
        "print('The average number of words in the files is', sum(numWords)/len(numWords))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive files finished\n",
            "Negative files finished\n",
            "The total number of files is 25000\n",
            "The total number of words in the files is 5844680\n",
            "The average number of words in the files is 233.7872\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}